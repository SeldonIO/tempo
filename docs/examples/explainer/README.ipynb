{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef410d1",
   "metadata": {},
   "source": [
    "# Model Explainer Example\n",
    "\n",
    "![architecture](architecture.png)\n",
    "\n",
    "In this example we will:\n",
    "\n",
    "  * [Describe the project structure](#Project-Structure)\n",
    "  * [Train some models](#Train-Models)\n",
    "  * [Create Tempo artifacts](#Create-Tempo-Artifacts)\n",
    "  * [Run unit tests](#Unit-Tests)\n",
    "  * [Save python environment for our classifier](#Save-Classifier-Environment)\n",
    "  * [Test Locally on Docker](#Test-Locally-on-Docker)\n",
    "  * [Production on Kubernetes via Tempo](#Production-Option-1-(Deploy-to-Kubernetes-with-Tempo))\n",
    "  * [Prodiuction on Kuebrnetes via GitOps](#Production-Option-2-(Gitops))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b5277",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ce5e8",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ca70f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34martifacts\u001b[00m\r\n",
      "│   ├── \u001b[01;34mexplainer\u001b[00m\r\n",
      "│   └── \u001b[01;34mmodel\u001b[00m\r\n",
      "├── \u001b[01;34mk8s\u001b[00m\r\n",
      "│   └── \u001b[01;34mrbac\u001b[00m\r\n",
      "└── \u001b[01;34msrc\u001b[00m\r\n",
      "    ├── constants.py\r\n",
      "    ├── data.py\r\n",
      "    ├── explainer.py\r\n",
      "    ├── model.py\r\n",
      "    └── tempo.py\r\n",
      "\r\n",
      "6 directories, 5 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dad4f",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    " * This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    " * For this example we train sklearn and xgboost classification models for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42c20ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import json\n",
    "import tempo\n",
    "\n",
    "from tempo.utils import logger\n",
    "\n",
    "from src.constants import ARTIFACTS_FOLDER\n",
    "\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa35a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import AdultData\n",
    "\n",
    "data = AdultData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc17ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9656333333333333\n",
      "Test accuracy:  0.854296875\n"
     ]
    }
   ],
   "source": [
    "from src.model import train_model\n",
    "\n",
    "adult_model = train_model(ARTIFACTS_FOLDER, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7afce019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnchorTabular(meta={\n",
       "  'name': 'AnchorTabular',\n",
       "  'type': ['blackbox'],\n",
       "  'explanations': ['local'],\n",
       "  'params': {'disc_perc': (25, 50, 75), 'seed': 1}}\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.explainer import train_explainer\n",
    "\n",
    "train_explainer(ARTIFACTS_FOLDER, data, adult_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396b609",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8345fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import create_explainer, create_adult_model\n",
    "\n",
    "sklearn_model = create_adult_model()\n",
    "Explainer = create_explainer(sklearn_model)\n",
    "explainer = Explainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b0af26",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "import os\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "from alibi.utils.wrappers import ArgmaxTransformer\n",
    "from src.constants import ARTIFACTS_FOLDER, EXPLAINER_FOLDER, MODEL_FOLDER\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import PipelineModels\n",
    "from tempo.serve.utils import pipeline, predictmethod\n",
    "\n",
    "\n",
    "def create_adult_model() -> Model :\n",
    "    sklearn_model = Model(\n",
    "        name=\"income-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=os.path.join(ARTIFACTS_FOLDER, MODEL_FOLDER),\n",
    "        uri=\"gs://seldon-models/test/income/model\",\n",
    "    )\n",
    "\n",
    "    return sklearn_model\n",
    "\n",
    "def create_explainer(model: Model) -> Tuple[Model, Any]:\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"income-explainer\",\n",
    "        uri=\"s3://tempo/explainer/pipeline\",\n",
    "        local_folder=os.path.join(ARTIFACTS_FOLDER, EXPLAINER_FOLDER),\n",
    "        models=PipelineModels(sklearn=model),\n",
    "    )\n",
    "    class ExplainerPipeline(object):\n",
    "        def __init__(self):\n",
    "            pipeline = self.get_tempo()\n",
    "            models_folder = pipeline.details.local_folder\n",
    "\n",
    "            explainer_path = os.path.join(models_folder, \"explainer.dill\")\n",
    "            with open(explainer_path, \"rb\") as f:\n",
    "                self.explainer = dill.load(f)\n",
    "\n",
    "        def update_predict_fn(self, x):\n",
    "            if np.argmax(self.models.sklearn(x).shape) == 0:\n",
    "                self.explainer.predictor = self.models.sklearn\n",
    "                self.explainer.samplers[0].predictor = self.models.sklearn\n",
    "            else:\n",
    "                self.explainer.predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "                self.explainer.samplers[0].predictor = ArgmaxTransformer(self.models.sklearn)\n",
    "\n",
    "        @predictmethod\n",
    "        def explain(self, payload: np.ndarray, parameters: dict) -> str:\n",
    "            print(\"Explain called with \", parameters)\n",
    "            self.update_predict_fn(payload)\n",
    "            explanation = self.explainer.explain(payload, **parameters)\n",
    "            return explanation.to_json()\n",
    "\n",
    "    #explainer = ExplainerPipeline()\n",
    "    #return sklearn_model, explainer\n",
    "    return ExplainerPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6a4b",
   "metadata": {},
   "source": [
    "## Save Explainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e1f9017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting artifacts/explainer/conda.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile artifacts/explainer/conda.yaml\n",
    "name: tempo\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.7.9\n",
    "  - pip:\n",
    "    - alibi==0.5.8\n",
    "    - dill\n",
    "    - mlops-tempo\n",
    "    - mlserver==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c23ab3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/alejandro/miniconda3/envs/tempo-56577a22-797a-479e-a1f7-d01eabf38dcb' to '/home/alejandro/Programming/kubernetes/seldon/tempo/docs/examples/explainer/artifacts/explainer/environment.tar.gz'\n",
      "[########################################] | 100% Completed |  1min 12.1s\n"
     ]
    }
   ],
   "source": [
    "tempo.save(Explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a21d5",
   "metadata": {},
   "source": [
    "## Test Locally on Docker\n",
    "\n",
    "Here we test our models using production images but running locally on Docker. This allows us to ensure the final production deployed model will behave as expected when deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a39ade59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy_local\n",
    "remote_model = deploy_local(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb09a516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marital Status = Separated']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(remote_model.predict(payload=data.X_test[0:1], parameters={\"threshold\":0.90}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b22014e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Relationship = Unmarried', 'Sex = Female', 'Capital Gain <= 0.00', 'Marital Status = Separated', 'Education = Associates']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(remote_model.predict(payload=data.X_test[0:1], parameters={\"threshold\":0.99}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c6ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91f4d7",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    "### Prerequisites\n",
    " \n",
    "Create a Kind Kubernetes cluster with Minio and Seldon Core installed using Ansible as described [here](https://tempo.readthedocs.io/en/latest/overview/quickstart.html#kubernetes-cluster-with-seldon-core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8d2fb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret configured\r\n",
      "serviceaccount/tempo-pipeline unchanged\r\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline unchanged\r\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fa80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone-minio.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39ff404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo.upload(sklearn_model)\n",
    "tempo.upload(explainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c56b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions(**{\n",
    "        \"remote_options\": {\n",
    "            \"namespace\": \"production\",\n",
    "            \"authSecretName\": \"minio-secret\"\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f59b1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy_remote\n",
    "remote_model = deploy_remote(explainer, options=runtime_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97b59a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Marital Status = Separated', 'Sex = Female', 'Capital Gain <= 0.00']\n"
     ]
    }
   ],
   "source": [
    "r = json.loads(remote_model.predict(payload=data.X_test[0:1], parameters={\"threshold\":0.95}))\n",
    "print(r[\"data\"][\"anchor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c789f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7205b",
   "metadata": {},
   "source": [
    "## Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "yaml_str = k8s_runtime.manifest(explainer)\n",
    "\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kustomize build k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffbadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
