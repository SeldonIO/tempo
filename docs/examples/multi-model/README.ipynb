{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef410d1",
   "metadata": {},
   "source": [
    "# Tempo Multi-Model Introduction\n",
    "\n",
    "![architecture](architecture.png)\n",
    "\n",
    "In this multi-model introduction we will:\n",
    "\n",
    "  * [Describe the project structure](#Project-Structure)\n",
    "  * [Train some models](#Train-Models)\n",
    "  * [Create Tempo artifacts](#Create-Tempo-Artifacts)\n",
    "  * [Run unit tests](#Unit-Tests)\n",
    "  * [Save python environment for our classifier](#Save-Classifier-Environment)\n",
    "  * [Test Locally on Docker](#Test-Locally-on-Docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b5277",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ce5e8",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca70f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55dad4f",
   "metadata": {},
   "source": [
    "## Train Models\n",
    "\n",
    " * This section is where as a data scientist you do your work of training models and creating artfacts.\n",
    " * For this example we train sklearn and xgboost classification models for the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c20ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "import numpy as np\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2abd28",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/train.py\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from src.data import IrisData\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "SKLearnFolder = \"sklearn\"\n",
    "XGBoostFolder = \"xgboost\"\n",
    "\n",
    "\n",
    "def train_sklearn(data: IrisData, artifacts_folder: str):\n",
    "    logreg = LogisticRegression(C=1e5)\n",
    "    logreg.fit(data.X, data.y)\n",
    "    with open(f\"{artifacts_folder}/{SKLearnFolder}/model.joblib\", \"wb\") as f:\n",
    "        joblib.dump(logreg, f)\n",
    "\n",
    "\n",
    "def train_xgboost(data: IrisData, artifacts_folder: str):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(data.X, data.y)\n",
    "    clf.save_model(f\"{artifacts_folder}/{XGBoostFolder}/model.bst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import IrisData\n",
    "from src.train import train_sklearn, train_xgboost\n",
    "data = IrisData()\n",
    "train_sklearn(data, ARTIFACTS_FOLDER)\n",
    "train_xgboost(data, ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396b609",
   "metadata": {},
   "source": [
    "## Create Tempo Artifacts\n",
    "\n",
    " * Here we create the Tempo models and orchestration Pipeline for our final service using our models.\n",
    " * For illustration the final service will call the sklearn model and based on the result will decide to return that prediction or call the xgboost model and return that prediction instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8345fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import get_tempo_artifacts\n",
    "classifier, sklearn_model, xgboost_model = get_tempo_artifacts(ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0af26",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from src.train import SKLearnFolder, XGBoostFolder\n",
    "\n",
    "from tempo.serve.metadata import ModelFramework\n",
    "from tempo.serve.model import Model\n",
    "from tempo.serve.pipeline import Pipeline, PipelineModels\n",
    "from tempo.serve.utils import pipeline\n",
    "\n",
    "PipelineFolder = \"classifier\"\n",
    "SKLearnTag = \"sklearn prediction\"\n",
    "XGBoostTag = \"xgboost prediction\"\n",
    "\n",
    "\n",
    "def get_tempo_artifacts(artifacts_folder: str) -> Tuple[Pipeline, Model, Model]:\n",
    "\n",
    "    sklearn_model = Model(\n",
    "        name=\"test-iris-sklearn\",\n",
    "        platform=ModelFramework.SKLearn,\n",
    "        local_folder=f\"{artifacts_folder}/{SKLearnFolder}\",\n",
    "        uri=\"s3://tempo/basic/sklearn\",\n",
    "        description=\"An SKLearn Iris classification model\",\n",
    "    )\n",
    "\n",
    "    xgboost_model = Model(\n",
    "        name=\"test-iris-xgboost\",\n",
    "        platform=ModelFramework.XGBoost,\n",
    "        local_folder=f\"{artifacts_folder}/{XGBoostFolder}\",\n",
    "        uri=\"s3://tempo/basic/xgboost\",\n",
    "        description=\"An XGBoost Iris classification model\",\n",
    "    )\n",
    "\n",
    "    @pipeline(\n",
    "        name=\"classifier\",\n",
    "        uri=\"s3://tempo/basic/pipeline\",\n",
    "        local_folder=f\"{artifacts_folder}/{PipelineFolder}\",\n",
    "        models=PipelineModels(sklearn=sklearn_model, xgboost=xgboost_model),\n",
    "        description=\"A pipeline to use either an sklearn or xgboost model for Iris classification\",\n",
    "    )\n",
    "    def classifier(payload: np.ndarray) -> Tuple[np.ndarray, str]:\n",
    "        res1 = classifier.models.sklearn(input=payload)\n",
    "\n",
    "        if res1[0] == 1:\n",
    "            return res1, SKLearnTag\n",
    "        else:\n",
    "            return classifier.models.xgboost(input=payload), XGBoostTag\n",
    "\n",
    "    return classifier, sklearn_model, xgboost_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0525e",
   "metadata": {},
   "source": [
    "## Unit Tests\n",
    "\n",
    " * Here we run our unit tests to ensure the orchestration works before running on the actual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159cbec",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %load tests/test_tempo.py\n",
    "import numpy as np\n",
    "from src.tempo import SKLearnTag, XGBoostTag, get_tempo_artifacts\n",
    "\n",
    "\n",
    "def test_sklearn_model_used():\n",
    "    classifier, _, _ = get_tempo_artifacts(\"\")\n",
    "    classifier.models.sklearn = lambda input: np.array([[1]])\n",
    "    res, tag = classifier(np.array([[1, 2, 3, 4]]))\n",
    "    assert res[0][0] == 1\n",
    "    assert tag == SKLearnTag\n",
    "\n",
    "\n",
    "def test_xgboost_model_used():\n",
    "    classifier, _, _ = get_tempo_artifacts(\"\")\n",
    "    classifier.models.sklearn = lambda input: np.array([[0.2]])\n",
    "    classifier.models.xgboost = lambda input: np.array([[0.1]])\n",
    "    res, tag = classifier(np.array([[1, 2, 3, 4]]))\n",
    "    assert res[0][0] == 0.1\n",
    "    assert tag == XGBoostTag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pytest tests/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc6a4b",
   "metadata": {},
   "source": [
    "## Save Classifier Environment\n",
    "\n",
    " * In preparation for running our models we save the Python environment needed for the orchestration to run as defined by a `conda.yaml` in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat artifacts/classifier/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import save\n",
    "save(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a21d5",
   "metadata": {},
   "source": [
    "## Test Locally on Docker\n",
    "\n",
    " * Here we test our models using production images but running locally on Docker. This allows us to ensure the final production deployed model will behave as expected when deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ca263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy\n",
    "remote_model = deploy(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd609448",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.predict(np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637093d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91f4d7",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    "### Prerequisites\n",
    " \n",
    "Create a Kind Kubernetes cluster with Minio and Seldon Core installed using Ansible as described [here](../../overview/quickstart.md#kubernetes-cluster-with-seldon-core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d2fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(sklearn_model)\n",
    "upload(xgboost_model)\n",
    "upload(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import KubernetesOptions\n",
    "from tempo.seldon.k8s import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions(\n",
    "        k8s_options=KubernetesOptions(\n",
    "            namespace=\"production\",\n",
    "            authSecretName=\"minio-secret\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd0834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy\n",
    "remote_model = deploy(classifier, options=runtime_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remote_model.predict(payload=np.array([[0, 0, 0, 0]])))\n",
    "print(remote_model.predict(payload=np.array([[1, 2, 3, 4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d18e0",
   "metadata": {},
   "source": [
    "### Illustrate use of Deployed Model by Remote Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b36170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "models = k8s_runtime.list_models(namespace=\"production\")\n",
    "print(\"Name\\tDescription\")\n",
    "for model in models:\n",
    "    details = model.get_tempo().model_spec.model_details\n",
    "    print(f\"{details.name}\\t{details.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b46fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].predict(payload=np.array([[1, 2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7205b",
   "metadata": {},
   "source": [
    "###### Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.seldon.k8s import SeldonKubernetesRuntime\n",
    "from tempo.serve.metadata import RuntimeOptions, KubernetesOptions\n",
    "runtime_options = RuntimeOptions(\n",
    "        k8s_options=KubernetesOptions(\n",
    "            namespace=\"production\",\n",
    "            authSecretName=\"minio-secret\"\n",
    "        )\n",
    "    )\n",
    "k8s_runtime = SeldonKubernetesRuntime(runtime_options)\n",
    "yaml_str = k8s_runtime.manifest(classifier)\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748bd754",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kustomize build k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58360438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
