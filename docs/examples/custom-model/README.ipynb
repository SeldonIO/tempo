{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a Custom Model\n",
    "\n",
    "This example walks you through how to deploy a custom model with Tempo.\n",
    "In particular, we will walk you through how to write custom logic to run inference on a [numpyro model](http://num.pyro.ai/en/stable/).\n",
    "\n",
    "Note that we've picked `numpyro` for this example simply because it's not supported out of the box, but it should be possible to adapt this example easily to any other custom model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebooks needs to be run in the `tempo-examples` conda environment defined below. Create from project root folder:\n",
    "\n",
    "```bash\n",
    "conda env create --name tempo-examples --file conda/tempo-examples.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34martifacts\u001b[00m\r\n",
      "├── \u001b[01;34mk8s\u001b[00m\r\n",
      "│   └── \u001b[01;34mrbac\u001b[00m\r\n",
      "└── \u001b[01;34msrc\u001b[00m\r\n",
      "    ├── tempo.py\r\n",
      "    └── train.py\r\n",
      "\r\n",
      "4 directories, 2 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -P \"*.py\"  -I \"__init__.py|__pycache__\" -L 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The first step will be to train our model.\n",
    "This will be a very simple bayesian regression model, based on an example provided in the [`numpyro` docs](https://nbviewer.jupyter.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/bayesian_regression.ipynb).\n",
    "\n",
    "Since this is a probabilistic model, during training we will compute an approximation to the posterior distribution of our model using MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# %load  src/train.py\n",
    "# Original source code and more details can be found in:\n",
    "# https://nbviewer.jupyter.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/bayesian_regression.ipynb\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from jax import random\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from src.tempo import model_function\n",
    "\n",
    "\n",
    "def train():\n",
    "    DATASET_URL = \"https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/WaffleDivorce.csv\"\n",
    "    dset = pd.read_csv(DATASET_URL, sep=\";\")\n",
    "\n",
    "    standardize = lambda x: (x - x.mean()) / x.std()  # noqa: E731\n",
    "\n",
    "    dset[\"AgeScaled\"] = dset.MedianAgeMarriage.pipe(standardize)\n",
    "    dset[\"MarriageScaled\"] = dset.Marriage.pipe(standardize)\n",
    "    dset[\"DivorceScaled\"] = dset.Divorce.pipe(standardize)\n",
    "\n",
    "    # Start from this source of randomness. We will split keys for subsequent operations.\n",
    "    rng_key = random.PRNGKey(0)\n",
    "    rng_key, rng_key_ = random.split(rng_key)\n",
    "\n",
    "    num_warmup, num_samples = 1000, 2000\n",
    "\n",
    "    # Run NUTS.\n",
    "    kernel = NUTS(model_function)\n",
    "    mcmc = MCMC(kernel, num_warmup, num_samples)\n",
    "    mcmc.run(rng_key_, marriage=dset.MarriageScaled.values, divorce=dset.DivorceScaled.values)\n",
    "    mcmc.print_summary()\n",
    "    return mcmc\n",
    "\n",
    "\n",
    "def save(mcmc, folder: str):\n",
    "    import json\n",
    "\n",
    "    samples = mcmc.get_samples()\n",
    "    serialisable = {}\n",
    "    for k, v in samples.items():\n",
    "        serialisable[k] = np.asarray(v).tolist()\n",
    "\n",
    "    model_file_name = f\"{folder}/numpyro-divorce.json\"\n",
    "    with open(model_file_name, \"w\") as model_file:\n",
    "        json.dump(serialisable, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 3000/3000 [00:05<00:00, 547.59it/s, 3 steps of size 7.77e-01. acc. prob=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "         a     -0.00      0.11     -0.00     -0.17      0.17   1794.52      1.00\n",
      "        bM      0.35      0.13      0.35      0.14      0.56   1748.73      1.00\n",
      "     sigma      0.94      0.10      0.94      0.77      1.09   2144.79      1.00\n",
      "\n",
      "Number of divergences: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tempo.utils import logger\n",
    "import logging\n",
    "import numpy as np\n",
    "logger.setLevel(logging.ERROR)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "ARTIFACTS_FOLDER = os.getcwd()+\"/artifacts\"\n",
    "from src.train import train, save, model_function\n",
    "mcmc = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained model\n",
    "\n",
    "Now that we have _trained_ our model, the next step will be to save it so that it can be loaded afterwards at serving-time.\n",
    "Note that, since this is a probabilistic model, we will only need to save the traces that approximate the posterior distribution over latent parameters.\n",
    "\n",
    "This will get saved in a `numpyro-divorce.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(mcmc, ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving\n",
    "\n",
    "The next step will be to serve our model through Tempo. \n",
    "For that, we will implement a custom model to perform inference using our custom `numpyro` model.\n",
    "Once our custom model is defined, we will be able to deploy it on any of the available runtimes using the same environment that we used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom inference logic \n",
    "\n",
    "Our custom model will be responsible of:\n",
    "\n",
    "- Loading the model from the set samples we saved previously.\n",
    "- Running inference using our model structure, and the posterior approximated from the samples.\n",
    "\n",
    "With Tempo, this can be achieved as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# %load src/tempo.py\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import numpyro\n",
    "from numpyro import distributions as dist\n",
    "from numpyro.infer import Predictive\n",
    "from jax import random\n",
    "from tempo import model, ModelFramework\n",
    "\n",
    "def model_function(marriage : np.ndarray = None, age : np.ndarray = None, divorce : np.ndarray = None):\n",
    "    a = numpyro.sample('a', dist.Normal(0., 0.2))\n",
    "    M, A = 0., 0.\n",
    "    if marriage is not None:\n",
    "        bM = numpyro.sample('bM', dist.Normal(0., 0.5))\n",
    "        M = bM * marriage\n",
    "    if age is not None:\n",
    "        bA = numpyro.sample('bA', dist.Normal(0., 0.5))\n",
    "        A = bA * age\n",
    "    sigma = numpyro.sample('sigma', dist.Exponential(1.))\n",
    "    mu = a + M + A\n",
    "    numpyro.sample('obs', dist.Normal(mu, sigma), obs=divorce)\n",
    "\n",
    "\n",
    "def get_tempo_artifact(local_folder: str):\n",
    "    @model(\n",
    "        name='numpyro-divorce',\n",
    "        platform=ModelFramework.Custom,\n",
    "        local_folder=local_folder,\n",
    "        uri=\"s3://tempo/divorce\",\n",
    "    )\n",
    "    def numpyro_divorce(marriage: np.ndarray, age: np.ndarray) -> np.ndarray:\n",
    "        rng_key = random.PRNGKey(0)\n",
    "        predictions = numpyro_divorce.context.predictive_dist(\n",
    "            rng_key=rng_key,\n",
    "            marriage=marriage,\n",
    "            age=age\n",
    "        )\n",
    "\n",
    "        mean = predictions['obs'].mean(axis=0)\n",
    "        return np.asarray(mean)\n",
    "\n",
    "    @numpyro_divorce.loadmethod\n",
    "    def load_numpyro_divorce():\n",
    "        model_uri = os.path.join(\n",
    "            numpyro_divorce.details.local_folder,\n",
    "            \"numpyro-divorce.json\"\n",
    "        )\n",
    "\n",
    "        with open(model_uri) as model_file:\n",
    "            raw_samples = json.load(model_file)\n",
    "\n",
    "        samples = {}\n",
    "        for k, v in raw_samples.items():\n",
    "            samples[k] = np.array(v)\n",
    "\n",
    "        print(model_function.__module__)\n",
    "        numpyro_divorce.context.predictive_dist = Predictive(model_function, samples)\n",
    "\n",
    "    return numpyro_divorce\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tempo import get_tempo_artifact\n",
    "numpyro_divorce = get_tempo_artifact(ARTIFACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test our custom logic by running inference locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.673733]\n"
     ]
    }
   ],
   "source": [
    "marriage = np.array([28.0])\n",
    "age = np.array([63])\n",
    "pred = numpyro_divorce(marriage=marriage, age=age)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the  Model to Docker\n",
    "\n",
    "Finally, we'll be able to deploy our model using Tempo against one of the available runtimes (i.e. Kubernetes, Docker or Seldon Deploy).\n",
    "\n",
    "We'll deploy first to Docker to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts/conda.yaml\r\n"
     ]
    }
   ],
   "source": [
    "!ls artifacts/conda.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packages...\n",
      "Packing environment at '/home/clive/anaconda3/envs/tempo-792d47bc-3391-4a9b-949b-bc38fe1cd5dd' to '/home/clive/work/mlops/fork-tempo/docs/examples/custom-model/artifacts/environment.tar.gz'\n",
      "[########################################] | 100% Completed | 19.0s\n"
     ]
    }
   ],
   "source": [
    "from tempo.serve.loader import save\n",
    "save(numpyro_divorce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy_local\n",
    "remote_model = deploy_local(numpyro_divorce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test our model deployed in Docker as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.673733], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_model.predict(marriage=marriage, age=age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Option 1 (Deploy to Kubernetes with Tempo)\n",
    "\n",
    " * Here we illustrate how to run the final models in \"production\" on Kubernetes by using Tempo to deploy\n",
    " \n",
    "### Prerequisites\n",
    " \n",
    "Create a Kind Kubernetes cluster with Minio and Seldon Core installed using Ansible as described [here](https://tempo.readthedocs.io/en/latest/overview/quickstart.html#kubernetes-cluster-with-seldon-core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/minio-secret configured\r\n",
      "serviceaccount/tempo-pipeline unchanged\r\n",
      "role.rbac.authorization.k8s.io/tempo-pipeline unchanged\r\n",
      "rolebinding.rbac.authorization.k8s.io/tempo-pipeline-rolebinding unchanged\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f k8s/rbac -n production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.examples.minio import create_minio_rclone\n",
    "import os\n",
    "create_minio_rclone(os.getcwd()+\"/rclone.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.loader import upload\n",
    "upload(numpyro_divorce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo.serve.metadata import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions(**{\n",
    "        \"remote_options\": {\n",
    "            \"namespace\": \"production\",\n",
    "            \"authSecretName\": \"minio-secret\"\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import deploy_remote\n",
    "remote_model = deploy_remote(numpyro_divorce, options=runtime_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.673733], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_model.predict(marriage=marriage, age=age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model.undeploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Option 2 (Gitops)\n",
    "\n",
    " * We create yaml to provide to our DevOps team to deploy to a production cluster\n",
    " * We add Kustomize patches to modify the base Kubernetes yaml created by Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempo import manifest\n",
    "from tempo.serve.metadata import SeldonCoreOptions\n",
    "runtime_options = SeldonCoreOptions(**{\n",
    "        \"remote_options\": {\n",
    "            \"namespace\": \"production\",\n",
    "            \"authSecretName\": \"minio-secret\"\n",
    "        }\n",
    "    })\n",
    "yaml_str = manifest(numpyro_divorce, options=runtime_options)\n",
    "with open(os.getcwd()+\"/k8s/tempo.yaml\",\"w\") as f:\n",
    "    f.write(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1\r\n",
      "kind: SeldonDeployment\r\n",
      "metadata:\r\n",
      "  annotations:\r\n",
      "    seldon.io/tempo-description: \"\"\r\n",
      "    seldon.io/tempo-model: '{\"model_details\": {\"name\": \"numpyro-divorce\", \"local_folder\":\r\n",
      "      \"/home/clive/work/mlops/fork-tempo/docs/examples/custom-model/artifacts\", \"uri\":\r\n",
      "      \"s3://tempo/divorce\", \"platform\": \"custom\", \"inputs\": {\"args\": [{\"ty\": \"numpy.ndarray\",\r\n",
      "      \"name\": \"marriage\"}, {\"ty\": \"numpy.ndarray\", \"name\": \"age\"}]}, \"outputs\": {\"args\":\r\n",
      "      [{\"ty\": \"numpy.ndarray\", \"name\": null}]}, \"description\": \"\"}, \"protocol\": \"tempo.kfserving.protocol.KFServingV2Protocol\",\r\n",
      "      \"runtime_options\": {\"runtime\": \"tempo.seldon.SeldonKubernetesRuntime\", \"state_options\":\r\n",
      "      {\"state_type\": \"LOCAL\", \"key_prefix\": \"\", \"host\": \"\", \"port\": \"\"}, \"insights_options\":\r\n",
      "      {\"worker_endpoint\": \"\", \"batch_size\": 1, \"parallelism\": 1, \"retries\": 3, \"window_time\":\r\n",
      "      0, \"mode_type\": \"NONE\", \"in_asyncio\": false}, \"ingress_options\": {\"ingress\":\r\n",
      "      \"tempo.ingress.istio.IstioIngress\", \"ssl\": false, \"verify_ssl\": true}, \"replicas\":\r\n",
      "      1, \"minReplicas\": null, \"maxReplicas\": null, \"authSecretName\": \"minio-secret\",\r\n",
      "      \"serviceAccountName\": null, \"add_svc_orchestrator\": false, \"namespace\": \"production\"}}'\r\n",
      "  labels:\r\n",
      "    seldon.io/tempo: \"true\"\r\n",
      "  name: numpyro-divorce\r\n",
      "  namespace: production\r\n",
      "spec:\r\n",
      "  predictors:\r\n",
      "  - annotations:\r\n",
      "      seldon.io/no-engine: \"true\"\r\n",
      "    componentSpecs:\r\n",
      "    - spec:\r\n",
      "        containers:\r\n",
      "        - name: classifier\r\n",
      "          resources:\r\n",
      "            limits:\r\n",
      "              cpu: 1\r\n",
      "              memory: 1Gi\r\n",
      "            requests:\r\n",
      "              cpu: 500m\r\n",
      "              memory: 500Mi\r\n",
      "    graph:\r\n",
      "      envSecretRefName: minio-secret\r\n",
      "      implementation: TEMPO_SERVER\r\n",
      "      modelUri: s3://tempo/divorce\r\n",
      "      name: numpyro-divorce\r\n",
      "      serviceAccountName: tempo-pipeline\r\n",
      "      type: MODEL\r\n",
      "    name: default\r\n",
      "    replicas: 1\r\n",
      "  protocol: kfserving\r\n"
     ]
    }
   ],
   "source": [
    "!kustomize build k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
